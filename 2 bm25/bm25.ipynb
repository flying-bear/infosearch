{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "bm25.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zybQGEZ-fkKS"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flying-bear/infosearch/blob/master/bm25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqz7UrcafkFN",
        "colab_type": "text"
      },
      "source": [
        "## Объяснение, почему всё так грустно и медленно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cedogW_ifkFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ec5e5df3-5cbe-4719-d211-52b8b8e38bbf"
      },
      "source": [
        "import psutil\n",
        "env_info = dict(psutil.virtual_memory()._asdict())\n",
        "for key in env_info:\n",
        "    if key != 'percent':\n",
        "        print(key, str(env_info[key] // 1000000000), 'Gb')\n",
        "    else:\n",
        "        print(key, str(env_info[key])+'%')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 13 Gb\n",
            "available 12 Gb\n",
            "percent 6.0%\n",
            "used 0 Gb\n",
            "free 11 Gb\n",
            "active 0 Gb\n",
            "inactive 1 Gb\n",
            "buffers 0 Gb\n",
            "cached 1 Gb\n",
            "shared 0 Gb\n",
            "slab 0 Gb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmmjrC7sfkFW",
        "colab_type": "text"
      },
      "source": [
        "## Лекция 2  BM5    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RgssOQSfkF5",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk0hNWsPfkGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "87f198fc-411e-46f6-b17b-031a9f652314"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "from math import log\n",
        "from pymystem3 import Mystem\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from time import time\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Q1MdfniSj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "92ce7500-fc46-42ea-c1a6-9f2df18f2795"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFaztyb5fkGb",
        "colab_type": "text"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkkeoMLMfkGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 2.0\n",
        "trained_size = 2000\n",
        "N = trained_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqYsPIewfkG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = Mystem()\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r-sA2XifkG4",
        "colab_type": "text"
      },
      "source": [
        "__important data-independent functions__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78vfX1zfkG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def enum_sort(arr): # takes a list and returns a list of ids in the decreasing order of the values from the input\n",
        "    return [x[0] for x in sorted(enumerate(arr), key=lambda x:x[1], reverse=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwVQjpq2fkG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize(text):\n",
        "    return [morph.lemmatize(token)[0] for token in nltk.word_tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbWoaL44fkHC",
        "colab_type": "text"
      },
      "source": [
        "### Pre-compute data-dependednt constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MZMOrvdfkHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c7b1cdc6-f6e7-4276-b323-6f8d02133d7a"
      },
      "source": [
        "questions = pd.read_csv('gdrive/My Drive/studies/HSE/prog/infosearch/2 bm25/quora_question_pairs_rus.csv', index_col=0).dropna()\n",
        "questions.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
              "      <td>что произойдет, если правительство Индии украд...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
              "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
              "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
              "      <td>какая рыба выживет в соленой воде</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
              "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... is_duplicate\n",
              "0        Какова история кохинор кох-и-ноор-бриллиант  ...            0\n",
              "1  как я могу увеличить скорость моего интернет-с...  ...            0\n",
              "2  почему я мысленно очень одинок, как я могу это...  ...            0\n",
              "3  которые растворяют в воде быстро сахарную соль...  ...            0\n",
              "4  астрология: я - луна-колпачок из козерога и кр...  ...            1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_h9TRfKfkHt",
        "colab_type": "text"
      },
      "source": [
        "__only some texts will be used, a part defined by trained_size constant above__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqgdANqjfkHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = questions[:trained_size]['question2'].tolist()\n",
        "## train_texts = [' '.join(lemmatize(text)) for text in train_texts] ## адово долго!!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLneUzCofkH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('lemmatized.json', 'w') as f:\n",
        "    f.write(json.dumps(train_texts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQNd-X80fkH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('lemmatized.json', 'r') as f:\n",
        "    train_texts = json.loads(f.read())[:trained_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FCZArxYfkID",
        "colab_type": "text"
      },
      "source": [
        "__define mean text length__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgmw7JIpfkIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "229d7c50-5a08-4eff-a513-aaa525bd9947"
      },
      "source": [
        "lens = [len(text.split()) for text in train_texts]\n",
        "avgdl = sum(lens)/N\n",
        "avgdl"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.5675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1blnKTUWfkIU",
        "colab_type": "text"
      },
      "source": [
        "__precompute a count matrix__\n",
        "<br> rows - documents\n",
        "<br> columns - words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoukPTqSfkIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f590a77-cd26-41d7-bd5d-5b62f727b74a"
      },
      "source": [
        "X = vectorizer.fit_transform(train_texts)\n",
        "count_matrix = X.toarray()\n",
        "count_matrix.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6632)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM8YeQIXfkIk",
        "colab_type": "text"
      },
      "source": [
        "__precompute tfs__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DP_yWLVfkIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a979d53c-ef5d-4ff1-e2aa-c1a6d3788b62"
      },
      "source": [
        "tf_matrix = count_matrix / np.array(lens).reshape((-1, 1))\n",
        "tf_matrix"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CR09SQ1fkIt",
        "colab_type": "text"
      },
      "source": [
        "get a vocabulary that has the same indexation as the rows of the count matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZggsEtffkIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "3a570b91-0086-4c9c-9ae5-8629b39bee13"
      },
      "source": [
        "vocabulary = vectorizer.get_feature_names()\n",
        "vocabulary[1030:1040]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['вашего',\n",
              " 'вашей',\n",
              " 'вашем',\n",
              " 'вашему',\n",
              " 'ваши',\n",
              " 'вашим',\n",
              " 'ваших',\n",
              " 'вашу',\n",
              " 'вблизи',\n",
              " 'введение']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Rxm_PEfkI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text, lemm=False):\n",
        "    if lemm:\n",
        "        words = lemmatize(text)\n",
        "    else:\n",
        "        words = nltk.word_tokenize(text)\n",
        "    query_modified = list(set(words).intersection(set(vocabulary)))  \n",
        "    return query_modified"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWnhV6ECfkJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6bf12a22-5f85-4515-ee35-f1d25fff26ef"
      },
      "source": [
        "q = 'БЛЯТЬ!111 Я ЗАЕБАЛАСЬ Вороны!22 ебутся в воде !11'\n",
        "preprocess(q)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['22', '11', 'воде']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn8GhxXWfkJh",
        "colab_type": "text"
      },
      "source": [
        "__get idfs__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y86TFJuqfkJi",
        "colab_type": "text"
      },
      "source": [
        "a list of number of docs with a given word for each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOrBYDdyfkJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d04f9c70-3c85-4e59-8d36-a7a36d3f2c23"
      },
      "source": [
        "in_n_docs = np.count_nonzero(count_matrix, axis=0)\n",
        "in_n_docs"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 14,  7, ...,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uTk4E1wfkJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IDF_modified(word):\n",
        "    word_id = vocabulary.index(word)\n",
        "    n = in_n_docs[word_id]\n",
        "    return log((N - n + 0.5) / (n + 0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OABH0DMdfkJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "203367e4-8f48-4316-adc7-c6a911948f39"
      },
      "source": [
        "IDF_modified('воде')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.195187320178709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ATHstoIfkJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "79288576-3bff-4fd6-f4c5-f45c7dbf5981"
      },
      "source": [
        "idfs = [IDF_modified(word) for word in vocabulary]\n",
        "idfs[1000:1010]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.6838614462772235,\n",
              " 7.195187320178709,\n",
              " 5.893901832250363,\n",
              " 7.195187320178709,\n",
              " 7.195187320178709,\n",
              " 7.195187320178709,\n",
              " 7.195187320178709,\n",
              " 7.195187320178709,\n",
              " 7.195187320178709,\n",
              " 7.195187320178709]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ufzWKKxfkKG",
        "colab_type": "text"
      },
      "source": [
        "## Функция ранжирования bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai9pLprbfkKH",
        "colab_type": "text"
      },
      "source": [
        "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
        "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
        "\n",
        "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
        "где   \n",
        ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
        "$l(d)$ - длина документа (количество слов в нём)   \n",
        "*avgdl* — средняя длина документа в коллекции    \n",
        "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
        "$$$$\n",
        "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
        "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
        ">> где $N$ - общее количество документов в коллекции   \n",
        "$n(q_i)$ — количество документов, содержащих $q_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO8iIbGVfkKI",
        "colab_type": "text"
      },
      "source": [
        "### implement tf part of the formula"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENyM2U-pfkKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modify_tf(tf_value, doc_index, b=0.75):\n",
        "    l = lens[doc_index]\n",
        "    return (tf_value * (k + 1.0))/(tf_value + k * (1.0 - b + b * (l/avgdl)))\n",
        "\n",
        "def modify_tf_matrix(tf_matrix, b=0.75): \n",
        "    enumed =  np.ndenumerate(tf_matrix)\n",
        "    for i, tf_value in enumed:\n",
        "        doc_index = i[0]\n",
        "        tf_matrix[i] = modify_tf(tf_value, doc_index, b)\n",
        "    return tf_matrix*idfs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajcgP-qqfkKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "43fd5c41-888f-426b-87de-aa9b2f0c23f2"
      },
      "source": [
        "modified_tf_matrix = modify_tf_matrix(tf_matrix)\n",
        "modified_tf_matrix"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zybQGEZ-fkKS",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 1__:    \n",
        "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
        "\n",
        "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
        "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian).\n",
        "\n",
        "__НА СТА ТЫСЯЧАХ НИКАК НЕ МОГУ, У МЕНЯ ОНО НА ДВУХ ТЫСЯЧАХ (trained_size in constants) МИНУТУ КРУТИТСЯ!!11__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWak5xrffkKY",
        "colab_type": "text"
      },
      "source": [
        "### define two bm25 implementations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxMTEFiifkKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### реализуйте эту функцию ранжирования векторно\n",
        "def bm25_vector(query, lemm=False):\n",
        "    vector = np.array(vectorizer.transform([' '.join(preprocess(query, lemm))]).todense())[0]\n",
        "    binary_vector = np.vectorize(lambda x: 1.0 if x != 0.0 else 0.0)(vector) ## neutralizes duplictes in the query (non-lineraity)\n",
        "    return modified_tf_matrix.dot(binary_vector) ## bm25 близость для каждого документа"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5kIaLYAfkKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### реализуйте эту функцию ранжирования итеративно\n",
        "def bm25_iter(query, lemm=False):\n",
        "    query_words = preprocess(query, lemm)\n",
        "    relevance = []\n",
        "    for i in range(N):\n",
        "        doc_index = i\n",
        "        doc_bm25 = 0.0\n",
        "        for word in set(query_words): ## set neutralizes duplictes in the query\n",
        "            word_index = vocabulary.index(word)\n",
        "            tf_value = tf_matrix[(doc_index, word_index)]\n",
        "            doc_bm25 += idfs[word_index] * modify_tf(tf_value, doc_index)\n",
        "        relevance.append(doc_bm25)\n",
        "    return relevance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAHs2OwwfkKs",
        "colab_type": "text"
      },
      "source": [
        "__Compare performance__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hmDhqdMfkKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = 'если честно, мне кажется, что мой итеративный алгоритм работает очень плохо 11 !!'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU7GjD3XfkKy",
        "colab_type": "code",
        "colab": {},
        "outputId": "7af7b88d-501c-4b54-db97-52aa2431b459"
      },
      "source": [
        "start = time()\n",
        "print(len(bm25_vector(query)))\n",
        "print('TIME non-lemmatized query: ' + str(time() - start))\n",
        "start = time()\n",
        "print(len(bm25_vector(query, lemm=True)))\n",
        "print('TIME lemmatized query: ' + str(time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "TIME non-lemmatized query: 0.027019262313842773\n",
            "2000\n",
            "TIME lemmatized query: 40.780805826187134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6knCiVzfkK2",
        "colab_type": "code",
        "colab": {},
        "outputId": "9de66407-857b-4391-c349-f5749b8e897c"
      },
      "source": [
        "start = time()\n",
        "print(len(bm25_iter(query)))\n",
        "print('TIME non-lemmatized query:', str(time() - start))\n",
        "start = time()\n",
        "print(len(bm25_iter(query, lemm=True)))\n",
        "print('TIME lemmatized query:', str(time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "TIME non-lemmatized query: 3.587538003921509\n",
            "2000\n",
            "TIME lemmatized query: 45.14999866485596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZP-yUZhfkK7",
        "colab_type": "text"
      },
      "source": [
        "__quod erat demonstrandum!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjSEHGpEfkLE",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 2__:    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl0mc626fkLF",
        "colab_type": "text"
      },
      "source": [
        "Выведите 10 первых результатов и их близость по метрике BM25 по запросу *рождественские каникулы* на нашем корпусе  Quora question pairs. \n",
        "\n",
        "__выведу только поиск на первых 2000 (trained_size in constants) документов, должно работать вообще, но моё железо не тянет__<br>\n",
        "__по *рождественским каникулам* в первых 2000 доков ничего нет, так что на примере другой query__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2kjPHf_fkLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search(query, lemm=False, n=N, nonzero=False, vector=True): \n",
        "    '''\n",
        "    searches a given query, returns top n results, by default n = all found (the legth of collection)\n",
        "    vector flag defines the algorythm (vector is used by default) \n",
        "    return format: [(document rank, document id, document text, bm_25), ...]\n",
        "    '''\n",
        "    if vector:\n",
        "        bms = bm25_vector(query, lemm)\n",
        "    else:\n",
        "        bms = bm25_iter(query, lemm)\n",
        "    relevance_sorted_document_ids_top_n = enum_sort(bms)[:n]\n",
        "    return [(rank, index, np.array(train_texts)[index], bms[index]) for rank, index in enumerate(relevance_sorted_document_ids_top_n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u8KGFB7fkLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "c286712b-175d-4ded-c521-398b15444d77"
      },
      "source": [
        "query = 'война с водой'\n",
        "print('query:', query, '\\n')\n",
        "start = time()\n",
        "response = search(query, n=10)\n",
        "print('TIME non-lemmatized query:', str(time() - start), '\\n')\n",
        "for rank, document_index, text, bm_25 in response:\n",
        "    print('relevance rank:', rank+1)\n",
        "    print('document:', text)\n",
        "    print('bm_25 =', bm_25, '\\n')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "query: война с водой \n",
            "\n",
            "TIME non-lemmatized query: 0.03602194786071777 \n",
            "\n",
            "relevance rank: 1\n",
            "document: мировая война\n",
            "bm_25 = 9.364436241738273 \n",
            "\n",
            "relevance rank: 2\n",
            "document: мировая война iii неизбежна\n",
            "bm_25 = 5.224180363292414 \n",
            "\n",
            "relevance rank: 3\n",
            "document: насколько близка мировая война iii\n",
            "bm_25 = 3.840680146419764 \n",
            "\n",
            "relevance rank: 4\n",
            "document: что такое сирийская гражданская война\n",
            "bm_25 = 3.840680146419764 \n",
            "\n",
            "relevance rank: 5\n",
            "document: можно использовать сенсорные экраны под водой\n",
            "bm_25 = 3.381176819675889 \n",
            "\n",
            "relevance rank: 6\n",
            "document: как работают бассейны с морской водой\n",
            "bm_25 = 3.381176819675889 \n",
            "\n",
            "relevance rank: 7\n",
            "document: 3-я мировая война неизбежна, чем ожидалось\n",
            "bm_25 = 2.8476281473900436 \n",
            "\n",
            "relevance rank: 8\n",
            "document: 3-я мировая война неизбежна, чем ожидалось\n",
            "bm_25 = 2.8476281473900436 \n",
            "\n",
            "relevance rank: 9\n",
            "document: будет ли ядерная война между Индией и Пакистаном\n",
            "bm_25 = 1.637820508863782 \n",
            "\n",
            "relevance rank: 10\n",
            "document: почему важно промыть соленой водой после удаления зубов мудрости\n",
            "bm_25 = 1.511994306864634 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEL_7vrIfkL4",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 3__:    \n",
        "\n",
        "Посчитайте точность поиска при \n",
        "1. BM25, b=0.75 \n",
        "2. BM15, b=0 \n",
        "3. BM11, b=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3D44OcdfkL6",
        "colab_type": "text"
      },
      "source": [
        "__let us set up the testing__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvzX3mzcfkMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a9a6d49e-a7db-41b8-b060-45dea145d6fa"
      },
      "source": [
        "testable = questions[(questions['is_duplicate'] == 1)&(questions.index < trained_size)][:100]\n",
        "testable.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
              "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>как я могу быть хорошим геологом?</td>\n",
              "      <td>что я должен делать, чтобы быть великим геологом?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>как мне читать и находить комментарии к YouTube</td>\n",
              "      <td>как я могу увидеть все мои комментарии к YouTube</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>что может сделать физику легкой для изучения</td>\n",
              "      <td>как вы можете легко научиться физике</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>какой был ваш первый сексуальный опыт, как</td>\n",
              "      <td>какой был ваш первый сексуальный опыт</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question1  ... is_duplicate\n",
              "4   астрология: я - луна-колпачок из козерога и кр...  ...            1\n",
              "6                   как я могу быть хорошим геологом?  ...            1\n",
              "10    как мне читать и находить комментарии к YouTube  ...            1\n",
              "11       что может сделать физику легкой для изучения  ...            1\n",
              "12         какой был ваш первый сексуальный опыт, как  ...            1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3enZRyofkMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "609440dd-7b30-454f-89fb-d7c5fa03787d"
      },
      "source": [
        "testable.index"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([  4,   6,  10,  11,  12,  14,  15,  17,  19,  28,  30,  31,  37,\n",
              "             47,  48,  49,  50,  52,  57,  61,  64,  65,  66,  70,  71,  72,\n",
              "             73,  78,  83,  84,  85,  87,  91,  92,  94,  99, 103, 106, 112,\n",
              "            119, 121, 124, 126, 134, 135, 142, 143, 151, 155, 157, 158, 159,\n",
              "            162, 164, 167, 172, 174, 175, 177, 178, 179, 181, 184, 187, 188,\n",
              "            189, 190, 192, 193, 196, 197, 198, 199, 202, 208, 209, 214, 215,\n",
              "            218, 219, 220, 223, 225, 228, 234, 235, 237, 241, 242, 243, 245,\n",
              "            248, 249, 250, 252, 254, 259, 260, 261, 266],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd8joekXfkMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7b8364a5-2294-4240-f1df-3ce0d9b81c84"
      },
      "source": [
        "search(questions.iloc[4]['question1'], n=5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1761, 'что такое свет из', 4.5068478582142895),\n",
              " (1, 494, 'что это за картина?', 4.3429893247048135),\n",
              " (2, 1432, 'мне все равно, что люди думают обо мне', 4.268822555802342),\n",
              " (3, 59, 'это надежные торренты', 3.9793498374648943),\n",
              " (4, 1669, 'как это влюбиться', 3.9793498374648943)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDI0tUQ1fkMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_q1_by_id(q1_index):\n",
        "    top_5_ids = [i for rank, i, text, bm_25 in search(questions.iloc[q1_index]['question1'], n=5)]\n",
        "    return 1.0 if q1_index in top_5_ids else 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP8Wf9ZcfkM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e34fa7f-e903-4864-be4f-f0b8562672f1"
      },
      "source": [
        "test_q1_by_id(6)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdW_-SdwfkNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_rank_of_q1_by_id(q1_index):\n",
        "    top_5_ids = [i for rank, i, text, bm_25 in search(questions.iloc[q1_index]['question1'], n=5)]\n",
        "    if q1_index in top_5_ids:\n",
        "        return 1/(top_5_ids.index(q1_index)+1)\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxjORcZufkNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddbbf0d0-4230-497d-d215-653cda142211"
      },
      "source": [
        "test_rank_of_q1_by_id(6)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDTCmcfafkOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_over_multiple_questions(b, ranked=False, testsize=100): # test for different bs\n",
        "    testable = questions[(questions['is_duplicate'] == 1)&(questions.index < trained_size)]\n",
        "    if testsize < len(testable):\n",
        "        testable = testable[:testsize]\n",
        "        print('testing on', testsize, 'questions')\n",
        "    else:\n",
        "        print('testing on', len(testable), 'questions')\n",
        "    modified_tf_matrix = modify_tf_matrix(tf_matrix, b=b)\n",
        "    if ranked:\n",
        "        test_q1 = test_rank_of_q1_by_id\n",
        "    else:\n",
        "        test_q1 = test_q1_by_id\n",
        "    hit_count = 0.0\n",
        "    for index in testable.index:\n",
        "        hit_count += test_q1(index)\n",
        "    return hit_count/len(testable.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPpeozWofkOr",
        "colab_type": "text"
      },
      "source": [
        "__tested on first 100 questions that have a hit__<br>\n",
        "__can be adjusted by changing *testsize* in test_over_multiple_questions call__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0RdNhGrfkOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "bcc585e4-843d-4c4c-af11-a25a43a832b5"
      },
      "source": [
        "bs = {'BM25': 0.75, 'BM15': 0, 'BM11': 1}\n",
        "for key in bs:\n",
        "    b = bs[key]\n",
        "    print(key, 'b =', b)\n",
        "    print('boolean precision:', test_over_multiple_questions(b, testsize=100))\n",
        "    print('rank precision:', test_over_multiple_questions(b, ranked=True, testsize=100))\n",
        "    print('')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BM25 b = 0.75\n",
            "testing on 100 questions\n",
            "boolean precision: 0.51\n",
            "testing on 100 questions\n",
            "rank precision: 0.3588333333333333\n",
            "\n",
            "BM15 b = 0\n",
            "testing on 100 questions\n",
            "boolean precision: 0.51\n",
            "testing on 100 questions\n",
            "rank precision: 0.3588333333333333\n",
            "\n",
            "BM11 b = 1\n",
            "testing on 100 questions\n",
            "boolean precision: 0.51\n",
            "testing on 100 questions\n",
            "rank precision: 0.3588333333333333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lm_R7rwfkOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "9424fa84-b3f3-4d8f-e098-3352a9e8d5a4"
      },
      "source": [
        "bs = {'BM25': 0.75, 'BM15': 0, 'BM11': 1}\n",
        "for key in bs:\n",
        "    b = bs[key]\n",
        "    print(key, 'b =', b)\n",
        "    print('boolean precision:', test_over_multiple_questions(b, testsize=500))\n",
        "    print('rank precision:', test_over_multiple_questions(b, ranked=True, testsize=500))\n",
        "    print('')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BM25 b = 0.75\n",
            "testing on 500 questions\n",
            "boolean precision: 0.564\n",
            "testing on 500 questions\n",
            "rank precision: 0.4258\n",
            "\n",
            "BM15 b = 0\n",
            "testing on 500 questions\n",
            "boolean precision: 0.564\n",
            "testing on 500 questions\n",
            "rank precision: 0.4258\n",
            "\n",
            "BM11 b = 1\n",
            "testing on 500 questions\n",
            "boolean precision: 0.564\n",
            "testing on 500 questions\n",
            "rank precision: 0.4258\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
