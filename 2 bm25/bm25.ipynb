{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение, почему всё так грустно и медленно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4 Gb\n",
      "available 1 Gb\n",
      "percent 69.1%\n",
      "used 2 Gb\n",
      "free 1 Gb\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "env_info = dict(psutil.virtual_memory()._asdict())\n",
    "for key in env_info:\n",
    "    if key != 'percent':\n",
    "        print(key, str(env_info[key] // 1000000000), 'Gb')\n",
    "    else:\n",
    "        print(key, str(env_info[key])+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from math import log\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2.0\n",
    "trained_size = 2000\n",
    "N = trained_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = Mystem()\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__important data-independent functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum_sort(arr): # takes a list and returns a list of ids in the decreasing order of the values from the input\n",
    "    return [x[0] for x in sorted(enumerate(arr), key=lambda x:x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return [morph.lemmatize(token)[0] for token in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, lemm=False):\n",
    "    if lemm:\n",
    "        words = lemmatize(text)\n",
    "    else:\n",
    "        words = nltk.word_tokenize(text)\n",
    "    query_modified = list(set(words).intersection(set(vocabulary)))  \n",
    "    return query_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['воде', '11', '22']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = 'БЛЯТЬ!111 Я ЗАЕБАЛАСЬ ВОороны!22 ебутся в воде !11'\n",
    "preprocess(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-compute data-dependednt constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('quora_question_pairs_rus.csv', index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
       "      <td>что произойдет, если правительство Индии украд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
       "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
       "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
       "      <td>какая рыба выживет в соленой воде</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
       "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0        Какова история кохинор кох-и-ноор-бриллиант   \n",
       "1  как я могу увеличить скорость моего интернет-с...   \n",
       "2  почему я мысленно очень одинок, как я могу это...   \n",
       "3  которые растворяют в воде быстро сахарную соль...   \n",
       "4  астрология: я - луна-колпачок из козерога и кр...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  что произойдет, если правительство Индии украд...             0  \n",
       "1  как повысить скорость интернета путем взлома ч...             0  \n",
       "2  найти остаток, когда математика 23 ^ 24 матема...             0  \n",
       "3                  какая рыба выживет в соленой воде             0  \n",
       "4  Я тройная луна-козерог и восхождение в козерог...             1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__only some texts will be used, a part defined by trained_size constant above__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = questions[:trained_size]['question2'].tolist()\n",
    "## train_texts = [' '.join(lemmatize(text)) for text in train_texts] ## адово долго!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemmatized.json', 'w') as f:\n",
    "    f.write(json.dumps(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemmatized.json', 'r') as f:\n",
    "    train_texts = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__define mean text length__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.5675"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(text.split()) for text in train_texts]\n",
    "avgdl = sum(lens)/N\n",
    "avgdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precompute a count matrix__\n",
    "<br> rows - documents\n",
    "<br> columns - words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6632)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(train_texts)\n",
    "count_matrix = X.toarray()\n",
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precompute tfs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix = count_matrix / np.array(lens).reshape((-1, 1))\n",
    "tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a vocabulary that has the same indexation as the rows of the count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вашего',\n",
       " 'вашей',\n",
       " 'вашем',\n",
       " 'вашему',\n",
       " 'ваши',\n",
       " 'вашим',\n",
       " 'ваших',\n",
       " 'вашу',\n",
       " 'вблизи',\n",
       " 'введение']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names()\n",
    "vocabulary[1030:1040]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get idfs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a list of number of docs with a given word for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 14,  7, ...,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_n_docs = np.count_nonzero(count_matrix, axis=0)\n",
    "in_n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF_modified(word):\n",
    "    word_id = vocabulary.index(word)\n",
    "    n = in_n_docs[word_id]\n",
    "    return log((N - n + 0.5) / (n + 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.195187320178709"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF_modified('воде')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.6838614462772235,\n",
       " 7.195187320178709,\n",
       " 5.893901832250363,\n",
       " 7.195187320178709,\n",
       " 7.195187320178709,\n",
       " 7.195187320178709,\n",
       " 7.195187320178709,\n",
       " 7.195187320178709,\n",
       " 7.195187320178709,\n",
       " 7.195187320178709]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs = [IDF_modified(word) for word in vocabulary]\n",
    "idfs[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement tf part of the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_tf(tf_value, doc_index, b=0.75):\n",
    "    l = lens[doc_index]\n",
    "    return (tf_value * (k + 1.0))/(tf_value + k * (1.0 - b + b * (l/avgdl)))\n",
    "\n",
    "def modify_tf_matrix(tf_matrix, b=0.75): \n",
    "    enumed =  np.ndenumerate(tf_matrix)\n",
    "    for i, tf_value in enumed:\n",
    "        doc_index = i[0]\n",
    "        tf_matrix[i] = modify_tf(tf_value, doc_index, b)\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_tf_matrix = modify_tf_matrix(tf_matrix)\n",
    "modified_tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
    "\n",
    "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
    "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian).\n",
    "\n",
    "__НА СТА ТЫСЯЧАХ НИКАК НЕ МОГУ, У МЕНЯ ОНО НА ДВУХ ТЫСЯЧАХ (trained_size in constants) МИНУТУ КРУТИТСЯ!!11__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define two bm25 implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования векторно\n",
    "def bm25_vector(query, lemm=False):\n",
    "    vector = np.array(vectorizer.transform([' '.join(preprocess(query, lemm))]).todense())[0]\n",
    "    binary_vector = np.vectorize(lambda x: 1.0 if x != 0.0 else 0.0)(vector) ## neutralizes duplictes in the query (non-lineraity)\n",
    "    idfs_from_query = np.array(idfs)*np.array(binary_vector)\n",
    "    return modified_tf_matrix.dot(idfs_from_query) ## bm25 близость для каждого документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования итеративно\n",
    "def bm25_iter(query, lemm=False):\n",
    "    query_words = preprocess(query, lemm)\n",
    "    relevance = []\n",
    "    for i in range(N):\n",
    "        doc_index = i\n",
    "        doc_bm25 = 0.0\n",
    "        for word in set(query_words): ## set neutralizes duplictes in the query\n",
    "            word_index = vocabulary.index(word)\n",
    "            tf_value = tf_matrix[(doc_index, word_index)]\n",
    "            doc_bm25 += idfs[word_index] * modify_tf(tf_value, doc_index)\n",
    "        relevance.append(doc_bm25)\n",
    "    return relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare performance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'если честно, мне кажется, что мой итеративный алгоритм работает очень плохо 11 !!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "TIME non-lemmatized query: 0.026017189025878906\n",
      "2000\n",
      "TIME lemmatized query: 50.16728663444519\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(len(bm25_vector(query)))\n",
    "print('TIME non-lemmatized query: ' + str(time() - start))\n",
    "start = time()\n",
    "print(len(bm25_vector(query, lemm=True)))\n",
    "print('TIME lemmatized query: ' + str(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "TIME non-lemmatized query: 2.4267168045043945\n",
      "2000\n",
      "TIME lemmatized query: 41.69868564605713\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(len(bm25_iter(query)))\n",
    "print('TIME non-lemmatized query:', str(time() - start))\n",
    "start = time()\n",
    "print(len(bm25_iter(query, lemm=True)))\n",
    "print('TIME lemmatized query:', str(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__quod erat demonstrandum!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите 10 первых результатов и их близость по метрике BM25 по запросу *рождественские каникулы* на нашем корпусе  Quora question pairs. \n",
    "\n",
    "__выведу только поиск на первых 2000 (trained_size in constants) документов, должно работать вообще, но моё железо не тянет__<br>\n",
    "__по *рождественским каникулам* в первых 2000 доков ничего нет, так что на примере другой query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, lemm=False, n=N, nonzero=False, vector=True): \n",
    "    '''\n",
    "    searches a given query, returns top n results, by default n = all found (the legth of collection)\n",
    "    vector flag defines the algorythm (vector is used by default) \n",
    "    return format: [(document rank, document id, document text, bm_25), ...]\n",
    "    '''\n",
    "    if vector:\n",
    "        bms = bm25_vector(query, lemm)\n",
    "    else:\n",
    "        bms = bm25_iter(query, lemm)\n",
    "    relevance_sorted_document_ids_top_n = enum_sort(bms)[:n]\n",
    "    return [(rank, index, np.array(train_texts)[index], bms[index]) for rank, index in enumerate(relevance_sorted_document_ids_top_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: война с водой \n",
      "\n",
      "TIME non-lemmatized query: 0.11207818984985352 \n",
      "\n",
      "relevance rank: 1\n",
      "document: мировая война\n",
      "bm_25 = 6.104036380117224 \n",
      "\n",
      "relevance rank: 2\n",
      "document: мировая война iii неизбежна\n",
      "bm_25 = 2.9111513574165624 \n",
      "\n",
      "relevance rank: 3\n",
      "document: насколько близка мировая война iii\n",
      "bm_25 = 2.1613334189965863 \n",
      "\n",
      "relevance rank: 4\n",
      "document: что такое сирийская гражданская война\n",
      "bm_25 = 2.1613334189965863 \n",
      "\n",
      "relevance rank: 5\n",
      "document: можно использовать сенсорные экраны под водой\n",
      "bm_25 = 1.9743315614418133 \n",
      "\n",
      "relevance rank: 6\n",
      "document: как работают бассейны с морской водой\n",
      "bm_25 = 1.9743315614418133 \n",
      "\n",
      "relevance rank: 7\n",
      "document: 3-я мировая война неизбежна, чем ожидалось\n",
      "bm_25 = 1.6627826423999825 \n",
      "\n",
      "relevance rank: 8\n",
      "document: 3-я мировая война неизбежна, чем ожидалось\n",
      "bm_25 = 1.6627826423999825 \n",
      "\n",
      "relevance rank: 9\n",
      "document: будет ли ядерная война между Индией и Пакистаном\n",
      "bm_25 = 1.066654762591441 \n",
      "\n",
      "relevance rank: 10\n",
      "document: почему важно промыть соленой водой после удаления зубов мудрости\n",
      "bm_25 = 1.0462340074760326 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'война с водой'\n",
    "print('query:', query, '\\n')\n",
    "start = time()\n",
    "response = search(query, n=10)\n",
    "print('TIME non-lemmatized query:', str(time() - start), '\\n')\n",
    "for rank, document_index, text, bm_25 in response:\n",
    "    print('relevance rank:', rank+1)\n",
    "    print('document:', text)\n",
    "    print('bm_25 =', bm_25, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "\n",
    "Посчитайте точность поиска при \n",
    "1. BM25, b=0.75 \n",
    "2. BM15, b=0 \n",
    "3. BM11, b=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__let us set up the testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
       "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>как я могу быть хорошим геологом?</td>\n",
       "      <td>что я должен делать, чтобы быть великим геологом?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>как мне читать и находить комментарии к YouTube</td>\n",
       "      <td>как я могу увидеть все мои комментарии к YouTube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>что может сделать физику легкой для изучения</td>\n",
       "      <td>как вы можете легко научиться физике</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>какой был ваш первый сексуальный опыт, как</td>\n",
       "      <td>какой был ваш первый сексуальный опыт</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question1  \\\n",
       "4   астрология: я - луна-колпачок из козерога и кр...   \n",
       "6                   как я могу быть хорошим геологом?   \n",
       "10    как мне читать и находить комментарии к YouTube   \n",
       "11       что может сделать физику легкой для изучения   \n",
       "12         какой был ваш первый сексуальный опыт, как   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "4   Я тройная луна-козерог и восхождение в козерог...             1  \n",
       "6   что я должен делать, чтобы быть великим геологом?             1  \n",
       "10   как я могу увидеть все мои комментарии к YouTube             1  \n",
       "11               как вы можете легко научиться физике             1  \n",
       "12              какой был ваш первый сексуальный опыт             1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testable = questions[(questions['is_duplicate'] == 1)&(questions.index < trained_size)][:100]\n",
    "testable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  4,   6,  10,  11,  12,  14,  15,  17,  19,  28,  30,  31,  37,\n",
       "             47,  48,  49,  50,  52,  57,  61,  64,  65,  66,  70,  71,  72,\n",
       "             73,  78,  83,  84,  85,  87,  91,  92,  94,  99, 103, 106, 112,\n",
       "            119, 121, 124, 126, 134, 135, 142, 143, 151, 155, 157, 158, 159,\n",
       "            162, 164, 167, 172, 174, 175, 177, 178, 179, 181, 184, 187, 188,\n",
       "            189, 190, 192, 193, 196, 197, 198, 199, 202, 208, 209, 214, 215,\n",
       "            218, 219, 220, 223, 225, 228, 234, 235, 237, 241, 242, 243, 245,\n",
       "            248, 249, 250, 252, 254, 259, 260, 261, 266],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testable.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1432, 'мне все равно, что люди думают обо мне', 2.894259740579932),\n",
       " (1, 1761, 'что такое свет из', 2.5114209976934676),\n",
       " (2, 494, 'что это за картина?', 2.4201115560053226),\n",
       " (3, 59, 'это надежные торренты', 2.304579802827789),\n",
       " (4, 1669, 'как это влюбиться', 2.304579802827789)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(questions.iloc[4]['question1'], n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q1_by_id(q1_index):\n",
    "    top_5_ids = [i for rank, i, text, bm_25 in search(questions.iloc[q1_index]['question1'], n=5)]\n",
    "    return 1.0 if q1_index in top_5_ids else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q1_by_id(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rank_of_q1_by_id(q1_index):\n",
    "    top_5_ids = [i for rank, i, text, bm_25 in search(questions.iloc[q1_index]['question1'], n=5)]\n",
    "    if q1_index in top_5_ids:\n",
    "        return 1/(top_5_ids.index(q1_index)+1)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rank_of_q1_by_id(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_over_multiple_questions(b, ranked=False, testsize=100): # test for different bs\n",
    "    testable = questions[(questions['is_duplicate'] == 1)&(questions.index < trained_size)]\n",
    "    if testsize < len(testable):\n",
    "        testable = testable[:testsize]\n",
    "        print('testing on', testsize, 'questions')\n",
    "    else:\n",
    "        print('testing on', len(testable), 'questions')\n",
    "    modified_tf_matrix = modify_tf_matrix(tf_matrix, b=b)\n",
    "    if ranked:\n",
    "        test_q1 = test_rank_of_q1_by_id\n",
    "    else:\n",
    "        test_q1 = test_q1_by_id\n",
    "    hit_count = 0.0\n",
    "    for index in testable.index:\n",
    "        hit_count += test_q1(index)\n",
    "    return (hit_count/len(testable.index), modified_tf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__tested on first 100 questions that have a hit__<br>\n",
    "__can be adjusted by changing *testsize* in test_over_multiple_questions call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on 10 questions\n"
     ]
    }
   ],
   "source": [
    "### это я пытаюсь найти источник флуктуации значений при одинаковом b\n",
    "prev, prev_mod_tf_matrix = test_over_multiple_questions(b=1, testsize=10)\n",
    "for i in range(3):\n",
    "    curr, curr_mod_tf_matrix = test_over_multiple_questions(b=1, testsize=10)\n",
    "    print(prev_mod_tf_matrix == curr_mod_tf_matrix)\n",
    "    print(prev == curr)\n",
    "    prev_mod_tf_matrix = curr_mod_tf_matrix\n",
    "    prev = curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 b = 0.75\n",
      "testing on 100 questions\n",
      "boolean precision: 0.52\n",
      "testing on 100 questions\n",
      "rank precision: 0.40266666666666673\n",
      "\n",
      "BM15 b = 0\n",
      "testing on 100 questions\n",
      "boolean precision: 0.59\n",
      "testing on 100 questions\n",
      "rank precision: 0.5481666666666667\n",
      "\n",
      "BM11 b = 1\n",
      "testing on 100 questions\n",
      "boolean precision: 0.61\n",
      "testing on 100 questions\n",
      "rank precision: 0.48566666666666675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bs = {'BM25': 0.75, 'BM15': 0, 'BM11': 1}\n",
    "for key in bs:\n",
    "    b = bs[key]\n",
    "    print(key, 'b =', b)\n",
    "    print('boolean precision:', test_over_multiple_questions(b, testsize=100))\n",
    "    print('rank precision:', test_over_multiple_questions(b, ranked=True, testsize=100))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
