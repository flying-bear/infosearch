{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k = 2.0\n",
    "b = 0.75\n",
    "\n",
    "\n",
    "def bm25() -> float:\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Напишите два поисковика на *BM25*. Один через подсчет метрики по формуле для каждой пары слово-документ, второй через умножение матрицы на вектор. \n",
    "\n",
    "Сравните время работы поиска на 100к запросах. В качестве корпуса возьмем \n",
    "[Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите 10 первых результатов и их близость по метрике BM25 по запросу **рождественские каникулы** на нашем корпусе  Quora question pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "\n",
    "Посчитайте точность поиска при \n",
    "1. BM25, b=0.75 \n",
    "2. BM15, b=0 \n",
    "3. BM11, b=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
